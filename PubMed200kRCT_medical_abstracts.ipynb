{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sevendi Eldrige Rifki Poluan沐･沐･沐･\n",
    "### Descriptions: NLP Fundamental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  6 17:02:19 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090         On | 00000000:65:00.0 Off |                  N/A |\n",
      "| 53%   42C    P8               46W / 390W|    189MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# working environment\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m161.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m675.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m670.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.0.0 pytz-2023.3 tzdata-2023.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m172.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m216.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.23.5)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.8/dist-packages (from pydot) (3.0.9)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.13.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_hub) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow_hub) (4.22.1)\n",
      "Installing collected packages: tensorflow_hub\n",
      "Successfully installed tensorflow_hub-0.13.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  fontconfig fontconfig-config fonts-dejavu-core fonts-liberation libann0\n",
      "  libbsd0 libcairo2 libcdt5 libcgraph6 libdatrie1 libfontconfig1 libfreetype6\n",
      "  libfribidi0 libgd3 libgraphite2-3 libgts-0.7-5 libgts-bin libgvc6 libgvpr2\n",
      "  libharfbuzz0b libice6 libjbig0 libjpeg-turbo8 libjpeg8 liblab-gamut1\n",
      "  libltdl7 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpathplan4\n",
      "  libpixman-1-0 libpng16-16 libsm6 libthai-data libthai0 libtiff5 libwebp6\n",
      "  libx11-6 libx11-data libxau6 libxaw7 libxcb-render0 libxcb-shm0 libxcb1\n",
      "  libxdmcp6 libxext6 libxmu6 libxpm4 libxrender1 libxt6 ucf x11-common\n",
      "Suggested packages:\n",
      "  gsfonts graphviz-doc libgd-tools\n",
      "The following NEW packages will be installed:\n",
      "  fontconfig fontconfig-config fonts-dejavu-core fonts-liberation graphviz\n",
      "  libann0 libbsd0 libcairo2 libcdt5 libcgraph6 libdatrie1 libfontconfig1\n",
      "  libfreetype6 libfribidi0 libgd3 libgraphite2-3 libgts-0.7-5 libgts-bin\n",
      "  libgvc6 libgvpr2 libharfbuzz0b libice6 libjbig0 libjpeg-turbo8 libjpeg8\n",
      "  liblab-gamut1 libltdl7 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0\n",
      "  libpathplan4 libpixman-1-0 libpng16-16 libsm6 libthai-data libthai0 libtiff5\n",
      "  libwebp6 libx11-6 libx11-data libxau6 libxaw7 libxcb-render0 libxcb-shm0\n",
      "  libxcb1 libxdmcp6 libxext6 libxmu6 libxpm4 libxrender1 libxt6 ucf x11-common\n",
      "0 upgraded, 53 newly installed, 0 to remove and 23 not upgraded.\n",
      "Need to get 8330 kB of archives.\n",
      "After this operation, 29.6 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libbsd0 amd64 0.10.0-1 [45.4 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libfribidi0 amd64 1.0.8-2ubuntu0.1 [24.2 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 ucf all 3.0038+nmu1 [51.6 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libpng16-16 amd64 1.6.37-2 [179 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libxau6 amd64 1:1.0.9-0ubuntu1 [7488 B]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libxdmcp6 amd64 1:1.1.3-0ubuntu1 [10.6 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb1 amd64 1.14-2 [44.7 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-data all 2:1.6.9-2ubuntu1.2 [113 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-6 amd64 2:1.6.9-2ubuntu1.2 [575 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 libxext6 amd64 2:1.3.4-0ubuntu1 [29.1 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libfreetype6 amd64 2.10.1-2ubuntu0.2 [341 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-dejavu-core all 2.37-1 [1041 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-liberation all 1:1.07.4-11 [822 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 fontconfig-config all 2.13.1-2ubuntu3 [28.8 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontconfig1 amd64 2.13.1-2ubuntu3 [114 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal/main amd64 fontconfig amd64 2.13.1-2ubuntu3 [171 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal/universe amd64 libann0 amd64 1.1.2+doc-7build1 [26.0 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal/universe amd64 libcdt5 amd64 2.42.2-3build2 [18.7 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal/universe amd64 libcgraph6 amd64 2.42.2-3build2 [41.3 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libjpeg-turbo8 amd64 2.0.3-0ubuntu1.20.04.3 [118 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal/main amd64 libjpeg8 amd64 8c-2ubuntu8 [2194 B]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libjbig0 amd64 2.1-3.1ubuntu0.20.04.1 [27.3 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwebp6 amd64 0.6.1-2ubuntu0.20.04.1 [185 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libtiff5 amd64 4.1.0+git191117-2ubuntu0.20.04.8 [163 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libxpm4 amd64 1:3.5.12-1ubuntu0.20.04.1 [34.6 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgd3 amd64 2.2.5-5.2ubuntu2.1 [118 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgts-0.7-5 amd64 0.7.6+darcs121130-4 [150 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpixman-1-0 amd64 0.38.4-0ubuntu2.1 [227 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-render0 amd64 1.14-2 [14.8 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-shm0 amd64 1.14-2 [5584 B]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu focal/main amd64 libxrender1 amd64 1:0.9.10-1 [18.7 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu focal/main amd64 libcairo2 amd64 1.16.0-4ubuntu1 [583 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu focal/main amd64 libltdl7 amd64 2.4.6-14 [38.5 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu focal/main amd64 libgraphite2-3 amd64 1.3.13-11build1 [73.5 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libharfbuzz0b amd64 2.6.4-1ubuntu4.2 [391 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu focal/main amd64 libthai-data all 0.1.28-3 [134 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu focal/main amd64 libdatrie1 amd64 0.2.12-3 [18.7 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu focal/main amd64 libthai0 amd64 0.1.28-3 [18.1 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu focal/main amd64 libpango-1.0-0 amd64 1.44.7-2ubuntu4 [162 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu focal/main amd64 libpangoft2-1.0-0 amd64 1.44.7-2ubuntu4 [34.9 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu focal/main amd64 libpangocairo-1.0-0 amd64 1.44.7-2ubuntu4 [24.8 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpathplan4 amd64 2.42.2-3build2 [21.9 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgvc6 amd64 2.42.2-3build2 [647 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgvpr2 amd64 2.42.2-3build2 [167 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu focal/universe amd64 liblab-gamut1 amd64 2.42.2-3build2 [177 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-common all 1:7.7+19ubuntu14 [22.3 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu focal/main amd64 libice6 amd64 2:1.0.10-0ubuntu1 [41.0 kB]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu focal/main amd64 libsm6 amd64 2:1.2.3-1 [16.1 kB]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu focal/main amd64 libxt6 amd64 1:1.1.5-1 [160 kB]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu focal/main amd64 libxmu6 amd64 2:1.1.3-0ubuntu1 [45.8 kB]\n",
      "Get:51 http://archive.ubuntu.com/ubuntu focal/main amd64 libxaw7 amd64 2:1.0.13-1 [173 kB]\n",
      "Get:52 http://archive.ubuntu.com/ubuntu focal/universe amd64 graphviz amd64 2.42.2-3build2 [590 kB]\n",
      "Get:53 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgts-bin amd64 0.7.6+darcs121130-4 [41.3 kB]\n",
      "Fetched 8330 kB in 12s (676 kB/s)                                              \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libbsd0:amd64.\n",
      "(Reading database ... 19765 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libbsd0_0.10.0-1_amd64.deb ...\n",
      "Unpacking libbsd0:amd64 (0.10.0-1) ...\n",
      "Selecting previously unselected package libfribidi0:amd64.\n",
      "Preparing to unpack .../01-libfribidi0_1.0.8-2ubuntu0.1_amd64.deb ...\n",
      "Unpacking libfribidi0:amd64 (1.0.8-2ubuntu0.1) ...\n",
      "Selecting previously unselected package ucf.\n",
      "Preparing to unpack .../02-ucf_3.0038+nmu1_all.deb ...\n",
      "Moving old data out of the way\n",
      "Unpacking ucf (3.0038+nmu1) ...\n",
      "Selecting previously unselected package libpng16-16:amd64.\n",
      "Preparing to unpack .../03-libpng16-16_1.6.37-2_amd64.deb ...\n",
      "Unpacking libpng16-16:amd64 (1.6.37-2) ...\n",
      "Selecting previously unselected package libxau6:amd64.\n",
      "Preparing to unpack .../04-libxau6_1%3a1.0.9-0ubuntu1_amd64.deb ...\n",
      "Unpacking libxau6:amd64 (1:1.0.9-0ubuntu1) ...\n",
      "Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../05-libxdmcp6_1%3a1.1.3-0ubuntu1_amd64.deb ...\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.3-0ubuntu1) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../06-libxcb1_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb1:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../07-libx11-data_2%3a1.6.9-2ubuntu1.2_all.deb ...\n",
      "Unpacking libx11-data (2:1.6.9-2ubuntu1.2) ...\n",
      "Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../08-libx11-6_2%3a1.6.9-2ubuntu1.2_amd64.deb ...\n",
      "Unpacking libx11-6:amd64 (2:1.6.9-2ubuntu1.2) ...\n",
      "Selecting previously unselected package libxext6:amd64.\n",
      "Preparing to unpack .../09-libxext6_2%3a1.3.4-0ubuntu1_amd64.deb ...\n",
      "Unpacking libxext6:amd64 (2:1.3.4-0ubuntu1) ...\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "Preparing to unpack .../10-libfreetype6_2.10.1-2ubuntu0.2_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.10.1-2ubuntu0.2) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../11-fonts-dejavu-core_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-1) ...\n",
      "Selecting previously unselected package fonts-liberation.\n",
      "Preparing to unpack .../12-fonts-liberation_1%3a1.07.4-11_all.deb ...\n",
      "Unpacking fonts-liberation (1:1.07.4-11) ...\n",
      "Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../13-fontconfig-config_2.13.1-2ubuntu3_all.deb ...\n",
      "Unpacking fontconfig-config (2.13.1-2ubuntu3) ...\n",
      "Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../14-libfontconfig1_2.13.1-2ubuntu3_amd64.deb ...\n",
      "Unpacking libfontconfig1:amd64 (2.13.1-2ubuntu3) ...\n",
      "Selecting previously unselected package fontconfig.\n",
      "Preparing to unpack .../15-fontconfig_2.13.1-2ubuntu3_amd64.deb ...\n",
      "Unpacking fontconfig (2.13.1-2ubuntu3) ...\n",
      "Selecting previously unselected package libann0.\n",
      "Preparing to unpack .../16-libann0_1.1.2+doc-7build1_amd64.deb ...\n",
      "Unpacking libann0 (1.1.2+doc-7build1) ...\n",
      "Selecting previously unselected package libcdt5:amd64.\n",
      "Preparing to unpack .../17-libcdt5_2.42.2-3build2_amd64.deb ...\n",
      "Unpacking libcdt5:amd64 (2.42.2-3build2) ...\n",
      "Selecting previously unselected package libcgraph6:amd64.\n",
      "Preparing to unpack .../18-libcgraph6_2.42.2-3build2_amd64.deb ...\n",
      "Unpacking libcgraph6:amd64 (2.42.2-3build2) ...\n",
      "Selecting previously unselected package libjpeg-turbo8:amd64.\n",
      "Preparing to unpack .../19-libjpeg-turbo8_2.0.3-0ubuntu1.20.04.3_amd64.deb ...\n",
      "Unpacking libjpeg-turbo8:amd64 (2.0.3-0ubuntu1.20.04.3) ...\n",
      "Selecting previously unselected package libjpeg8:amd64.\n",
      "Preparing to unpack .../20-libjpeg8_8c-2ubuntu8_amd64.deb ...\n",
      "Unpacking libjpeg8:amd64 (8c-2ubuntu8) ...\n",
      "Selecting previously unselected package libjbig0:amd64.\n",
      "Preparing to unpack .../21-libjbig0_2.1-3.1ubuntu0.20.04.1_amd64.deb ...\n",
      "Unpacking libjbig0:amd64 (2.1-3.1ubuntu0.20.04.1) ...\n",
      "Selecting previously unselected package libwebp6:amd64.\n",
      "Preparing to unpack .../22-libwebp6_0.6.1-2ubuntu0.20.04.1_amd64.deb ...\n",
      "Unpacking libwebp6:amd64 (0.6.1-2ubuntu0.20.04.1) ...\n",
      "Selecting previously unselected package libtiff5:amd64.\n",
      "Preparing to unpack .../23-libtiff5_4.1.0+git191117-2ubuntu0.20.04.8_amd64.deb ...\n",
      "Unpacking libtiff5:amd64 (4.1.0+git191117-2ubuntu0.20.04.8) ...\n",
      "Selecting previously unselected package libxpm4:amd64.\n",
      "Preparing to unpack .../24-libxpm4_1%3a3.5.12-1ubuntu0.20.04.1_amd64.deb ...\n",
      "Unpacking libxpm4:amd64 (1:3.5.12-1ubuntu0.20.04.1) ...\n",
      "Selecting previously unselected package libgd3:amd64.\n",
      "Preparing to unpack .../25-libgd3_2.2.5-5.2ubuntu2.1_amd64.deb ...\n",
      "Unpacking libgd3:amd64 (2.2.5-5.2ubuntu2.1) ...\n",
      "Selecting previously unselected package libgts-0.7-5:amd64.\n",
      "Preparing to unpack .../26-libgts-0.7-5_0.7.6+darcs121130-4_amd64.deb ...\n",
      "Unpacking libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
      "Selecting previously unselected package libpixman-1-0:amd64.\n",
      "Preparing to unpack .../27-libpixman-1-0_0.38.4-0ubuntu2.1_amd64.deb ...\n",
      "Unpacking libpixman-1-0:amd64 (0.38.4-0ubuntu2.1) ...\n",
      "Selecting previously unselected package libxcb-render0:amd64.\n",
      "Preparing to unpack .../28-libxcb-render0_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb-render0:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package libxcb-shm0:amd64.\n",
      "Preparing to unpack .../29-libxcb-shm0_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb-shm0:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package libxrender1:amd64.\n",
      "Preparing to unpack .../30-libxrender1_1%3a0.9.10-1_amd64.deb ...\n",
      "Unpacking libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Selecting previously unselected package libcairo2:amd64.\n",
      "Preparing to unpack .../31-libcairo2_1.16.0-4ubuntu1_amd64.deb ...\n",
      "Unpacking libcairo2:amd64 (1.16.0-4ubuntu1) ...\n",
      "Selecting previously unselected package libltdl7:amd64.\n",
      "Preparing to unpack .../32-libltdl7_2.4.6-14_amd64.deb ...\n",
      "Unpacking libltdl7:amd64 (2.4.6-14) ...\n",
      "Selecting previously unselected package libgraphite2-3:amd64.\n",
      "Preparing to unpack .../33-libgraphite2-3_1.3.13-11build1_amd64.deb ...\n",
      "Unpacking libgraphite2-3:amd64 (1.3.13-11build1) ...\n",
      "Selecting previously unselected package libharfbuzz0b:amd64.\n",
      "Preparing to unpack .../34-libharfbuzz0b_2.6.4-1ubuntu4.2_amd64.deb ...\n",
      "Unpacking libharfbuzz0b:amd64 (2.6.4-1ubuntu4.2) ...\n",
      "Selecting previously unselected package libthai-data.\n",
      "Preparing to unpack .../35-libthai-data_0.1.28-3_all.deb ...\n",
      "Unpacking libthai-data (0.1.28-3) ...\n",
      "Selecting previously unselected package libdatrie1:amd64.\n",
      "Preparing to unpack .../36-libdatrie1_0.2.12-3_amd64.deb ...\n",
      "Unpacking libdatrie1:amd64 (0.2.12-3) ...\n",
      "Selecting previously unselected package libthai0:amd64.\n",
      "Preparing to unpack .../37-libthai0_0.1.28-3_amd64.deb ...\n",
      "Unpacking libthai0:amd64 (0.1.28-3) ...\n",
      "Selecting previously unselected package libpango-1.0-0:amd64.\n",
      "Preparing to unpack .../38-libpango-1.0-0_1.44.7-2ubuntu4_amd64.deb ...\n",
      "Unpacking libpango-1.0-0:amd64 (1.44.7-2ubuntu4) ...\n",
      "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
      "Preparing to unpack .../39-libpangoft2-1.0-0_1.44.7-2ubuntu4_amd64.deb ...\n",
      "Unpacking libpangoft2-1.0-0:amd64 (1.44.7-2ubuntu4) ...\n",
      "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
      "Preparing to unpack .../40-libpangocairo-1.0-0_1.44.7-2ubuntu4_amd64.deb ...\n",
      "Unpacking libpangocairo-1.0-0:amd64 (1.44.7-2ubuntu4) ...\n",
      "Selecting previously unselected package libpathplan4:amd64.\n",
      "Preparing to unpack .../41-libpathplan4_2.42.2-3build2_amd64.deb ...\n",
      "Unpacking libpathplan4:amd64 (2.42.2-3build2) ...\n",
      "Selecting previously unselected package libgvc6.\n",
      "Preparing to unpack .../42-libgvc6_2.42.2-3build2_amd64.deb ...\n",
      "Unpacking libgvc6 (2.42.2-3build2) ...\n",
      "Selecting previously unselected package libgvpr2:amd64.\n",
      "Preparing to unpack .../43-libgvpr2_2.42.2-3build2_amd64.deb ...\n",
      "Unpacking libgvpr2:amd64 (2.42.2-3build2) ...\n",
      "Selecting previously unselected package liblab-gamut1:amd64.\n",
      "Preparing to unpack .../44-liblab-gamut1_2.42.2-3build2_amd64.deb ...\n",
      "Unpacking liblab-gamut1:amd64 (2.42.2-3build2) ...\n",
      "Selecting previously unselected package x11-common.\n",
      "Preparing to unpack .../45-x11-common_1%3a7.7+19ubuntu14_all.deb ...\n",
      "dpkg-query: no packages found matching nux-tools\n",
      "Unpacking x11-common (1:7.7+19ubuntu14) ...\n",
      "Selecting previously unselected package libice6:amd64.\n",
      "Preparing to unpack .../46-libice6_2%3a1.0.10-0ubuntu1_amd64.deb ...\n",
      "Unpacking libice6:amd64 (2:1.0.10-0ubuntu1) ...\n",
      "Selecting previously unselected package libsm6:amd64.\n",
      "Preparing to unpack .../47-libsm6_2%3a1.2.3-1_amd64.deb ...\n",
      "Unpacking libsm6:amd64 (2:1.2.3-1) ...\n",
      "Selecting previously unselected package libxt6:amd64.\n",
      "Preparing to unpack .../48-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
      "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
      "Selecting previously unselected package libxmu6:amd64.\n",
      "Preparing to unpack .../49-libxmu6_2%3a1.1.3-0ubuntu1_amd64.deb ...\n",
      "Unpacking libxmu6:amd64 (2:1.1.3-0ubuntu1) ...\n",
      "Selecting previously unselected package libxaw7:amd64.\n",
      "Preparing to unpack .../50-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
      "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
      "Selecting previously unselected package graphviz.\n",
      "Preparing to unpack .../51-graphviz_2.42.2-3build2_amd64.deb ...\n",
      "Unpacking graphviz (2.42.2-3build2) ...\n",
      "Selecting previously unselected package libgts-bin.\n",
      "Preparing to unpack .../52-libgts-bin_0.7.6+darcs121130-4_amd64.deb ...\n",
      "Unpacking libgts-bin (0.7.6+darcs121130-4) ...\n",
      "Setting up libgraphite2-3:amd64 (1.3.13-11build1) ...\n",
      "Setting up libpixman-1-0:amd64 (0.38.4-0ubuntu2.1) ...\n",
      "Setting up libxau6:amd64 (1:1.0.9-0ubuntu1) ...\n",
      "Setting up libdatrie1:amd64 (0.2.12-3) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up liblab-gamut1:amd64 (2.42.2-3build2) ...\n",
      "Setting up x11-common (1:7.7+19ubuntu14) ...\n",
      "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up libjbig0:amd64 (2.1-3.1ubuntu0.20.04.1) ...\n",
      "Setting up libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
      "Setting up libx11-data (2:1.6.9-2ubuntu1.2) ...\n",
      "Setting up libpathplan4:amd64 (2.42.2-3build2) ...\n",
      "Setting up libann0 (1.1.2+doc-7build1) ...\n",
      "Setting up libfribidi0:amd64 (1.0.8-2ubuntu0.1) ...\n",
      "Setting up libpng16-16:amd64 (1.6.37-2) ...\n",
      "Setting up libwebp6:amd64 (0.6.1-2ubuntu0.20.04.1) ...\n",
      "Setting up fonts-dejavu-core (2.37-1) ...\n",
      "Setting up ucf (3.0038+nmu1) ...\n",
      "Setting up libjpeg-turbo8:amd64 (2.0.3-0ubuntu1.20.04.3) ...\n",
      "Setting up libltdl7:amd64 (2.4.6-14) ...\n",
      "Setting up fonts-liberation (1:1.07.4-11) ...\n",
      "Setting up libthai-data (0.1.28-3) ...\n",
      "Setting up libcdt5:amd64 (2.42.2-3build2) ...\n",
      "Setting up libcgraph6:amd64 (2.42.2-3build2) ...\n",
      "Setting up libbsd0:amd64 (0.10.0-1) ...\n",
      "Setting up libjpeg8:amd64 (8c-2ubuntu8) ...\n",
      "Setting up libgts-bin (0.7.6+darcs121130-4) ...\n",
      "Setting up libice6:amd64 (2:1.0.10-0ubuntu1) ...\n",
      "Setting up libxdmcp6:amd64 (1:1.1.3-0ubuntu1) ...\n",
      "Setting up libxcb1:amd64 (1.14-2) ...\n",
      "Setting up libxcb-render0:amd64 (1.14-2) ...\n",
      "Setting up fontconfig-config (2.13.1-2ubuntu3) ...\n",
      "Setting up libxcb-shm0:amd64 (1.14-2) ...\n",
      "Setting up libthai0:amd64 (0.1.28-3) ...\n",
      "Setting up libfreetype6:amd64 (2.10.1-2ubuntu0.2) ...\n",
      "Setting up libgvpr2:amd64 (2.42.2-3build2) ...\n",
      "Setting up libx11-6:amd64 (2:1.6.9-2ubuntu1.2) ...\n",
      "Setting up libharfbuzz0b:amd64 (2.6.4-1ubuntu4.2) ...\n",
      "Setting up libtiff5:amd64 (4.1.0+git191117-2ubuntu0.20.04.8) ...\n",
      "Setting up libfontconfig1:amd64 (2.13.1-2ubuntu3) ...\n",
      "Setting up libsm6:amd64 (2:1.2.3-1) ...\n",
      "Setting up fontconfig (2.13.1-2ubuntu3) ...\n",
      "Regenerating fonts cache... done.\n",
      "Setting up libxpm4:amd64 (1:3.5.12-1ubuntu0.20.04.1) ...\n",
      "Setting up libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Setting up libpango-1.0-0:amd64 (1.44.7-2ubuntu4) ...\n",
      "Setting up libxext6:amd64 (2:1.3.4-0ubuntu1) ...\n",
      "Setting up libcairo2:amd64 (1.16.0-4ubuntu1) ...\n",
      "Setting up libgd3:amd64 (2.2.5-5.2ubuntu2.1) ...\n",
      "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
      "Setting up libpangoft2-1.0-0:amd64 (1.44.7-2ubuntu4) ...\n",
      "Setting up libpangocairo-1.0-0:amd64 (1.44.7-2ubuntu4) ...\n",
      "Setting up libxmu6:amd64 (2:1.1.3-0ubuntu1) ...\n",
      "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
      "Setting up libgvc6 (2.42.2-3build2) ...\n",
      "Setting up graphviz (2.42.2-3build2) ...\n",
      "Processing triggers for systemd (245.4-4ubuntu3.20) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install graphviz -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Import the necessary libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 17:02:28.463395: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-06 17:02:28.499156: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import tensorflow_hub as hub\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Download the PubMed200kRCT_medical_abstracts dataset, which is a collection of around 200,000 labelled Randomized Controlled Trial (RCT) abstracts, from the paper titled [\"PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts\"](https://arxiv.org/abs/1710.06071) published in 2017. For more detailed information about the datasets, please refer to the original paper.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pubmed-rct'...\n",
      "remote: Enumerating objects: 33, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 33 (delta 5), reused 5 (delta 5), pack-reused 25\u001b[K\n",
      "Unpacking objects: 100% (33/33), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PubMed_200k_RCT\r\n",
      "PubMed_200k_RCT_numbers_replaced_with_at_sign\r\n",
      "PubMed_20k_RCT\r\n",
      "PubMed_20k_RCT_numbers_replaced_with_at_sign\r\n",
      "README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt  test.txt  train.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/train.zip\n",
      "  inflating: pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/train.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/train.zip -d pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt  test.txt  train.txt  train.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Load the dataset from txt files and read their contents.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = open(\"pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/train.txt\", 'r').readlines()\n",
    "test_data = open(\"pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/test.txt\", 'r').readlines()\n",
    "val_data = open(\"pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/dev.txt\", 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24491034\\n',\n",
       " 'BACKGROUND\\tThe emergence of HIV as a chronic condition means that people living with HIV are required to take more responsibility for the self-management of their condition , including making physical , emotional and social adjustments .\\n',\n",
       " 'BACKGROUND\\tThis paper describes the design and evaluation of Positive Outlook , an online program aiming to enhance the self-management skills of gay men living with HIV .\\n']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Dataset Preparation: Separating Input Features and Target</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    all_data = []\n",
    "    one_abstract = ''\n",
    "    for line in data:\n",
    "        if line.startswith(\"###\"):\n",
    "            pass\n",
    "        elif line.isspace():\n",
    "            one_abstract = one_abstract.split(\"\\n\") \n",
    "            for i, text in enumerate(one_abstract):\n",
    "                dict_data = {}\n",
    "                split = text.split(\"\\t\")\n",
    "                if len(split) > 1: \n",
    "                    label = split[0]\n",
    "                    target = '' . join(split[1]).strip()\n",
    "                    dict_data['target'] = label\n",
    "                    dict_data['text'] = target\n",
    "                    dict_data['line_index'] = i + 1\n",
    "                    dict_data['total_lines'] = len(one_abstract) \n",
    "                    \n",
    "                    all_data.append(dict_data)\n",
    "                \n",
    "            one_abstract = '' \n",
    "        else:\n",
    "            one_abstract += line\n",
    "            \n",
    "    return all_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.DataFrame(prepare_data(train_data))\n",
    "test_raw = pd.DataFrame(prepare_data(test_data))\n",
    "val_raw = pd.DataFrame(prepare_data(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_index</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>The emergence of HIV as a chronic condition me...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>This paper describes the design and evaluation...</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>This study is designed as a randomised control...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>The intervention group will participate in the...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>The program is based on self-efficacy theory a...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text  line_index  \\\n",
       "0  BACKGROUND  The emergence of HIV as a chronic condition me...           1   \n",
       "1  BACKGROUND  This paper describes the design and evaluation...           2   \n",
       "2     METHODS  This study is designed as a randomised control...           3   \n",
       "3     METHODS  The intervention group will participate in the...           4   \n",
       "4     METHODS  The program is based on self-efficacy theory a...           5   \n",
       "\n",
       "   total_lines  \n",
       "0           12  \n",
       "1           12  \n",
       "2           12  \n",
       "3           12  \n",
       "4           12  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw, y_train_raw = train_raw.text, train_raw.target\n",
    "x_test_raw, y_test_raw = test_raw.text, test_raw.target\n",
    "x_val_raw, y_val_raw = val_raw.text, val_raw.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The emergence of HIV as a chronic condition means that people living with HIV are required to take more responsibility for the self-management of their condition , including making physical , emotional and social adjustments .',\n",
       " 'BACKGROUND')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_raw[0], y_train_raw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Convert the label into integer values for encoding in preparation to be fed into the network.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"笆ｸ\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"笆ｾ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw_en = encoder.transform(y_train_raw)\n",
    "y_test_raw_en = encoder.transform(y_test_raw)\n",
    "y_val_raw_en = encoder.transform(y_val_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 2, 2, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_raw_en[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Convert the dataset into a tensor format.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 17:03:00.949411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22054 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((x_train_raw[:], y_train_raw_en[:]))\n",
    "test = tf.data.Dataset.from_tensor_slices((x_test_raw, y_test_raw_en))\n",
    "val = tf.data.Dataset.from_tensor_slices((x_val_raw, y_val_raw_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "    Configure the token count and sequence length for text vectorization and embedding.\n",
    "</font>\n",
    "</br>\n",
    "    \n",
    "    APPROXIMATE_TOKEN_COUNT: I calculated the approximate token count based on the number of unique tokens in the entire training set.\n",
    "\n",
    "    SEQ_LENGTH: I determined the sequence length based on the occurrence of tokens in the dataset, where I selected the length that covers approximately 97% of the tokens in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "APPROXIMATE_TOKEN_COUNT = len(set(' ' . join(x_train_raw).split(' ')))\n",
    "SEQ_LENGTH = int(np.percentile([len(x) for x in x_train_raw], 97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326178, 314)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APPROXIMATE_TOKEN_COUNT, SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>We will set up the vectorization and embedding model to process the input sentences, focusing on **text-level features**.</font>\n",
    "    \n",
    "    The dataset adaptation process may take some time due to the large amount of data. To address this, you can consider using transfer learning by extracting pre-trained embeddings from existing models, which can provide better features and save time as well. But, in this case, we will not be using that approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorize = tf.keras.layers.TextVectorization(max_tokens=APPROXIMATE_TOKEN_COUNT,\n",
    "                                              output_mode=\"int\",\n",
    "                                              output_sequence_length=SEQ_LENGTH,\n",
    "                                              split=\"whitespace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855.8049010419927 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "vectorize.adapt(x_train_raw, batch_size=32)\n",
    "end_time = time.perf_counter()\n",
    "print(end_time - start_time, 'seconds') # 890.2296672859957 seconds in average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 314), dtype=int64, numpy=\n",
       "array([[   2, 3009,    3,  545,   25,    8,  241,  559,  970,   26,  656,\n",
       "        1234,    7,  545,   67,  408,    6, 2116,   59, 9855,   12,    2,\n",
       "        2288,    3,  123,  559,  309, 2220,  239, 1528,    4,  642, 4723,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize([x_train_raw[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = tf.keras.layers.Embedding(input_dim=APPROXIMATE_TOKEN_COUNT, \n",
    "                                      output_dim=256, \n",
    "                                      input_length=SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 314, 256), dtype=float32, numpy=\n",
       "array([[[-0.03431991, -0.04888877, -0.00974152, ..., -0.01552814,\n",
       "          0.02465305, -0.00084291],\n",
       "        [-0.00754689, -0.02949709, -0.00302827, ..., -0.03831697,\n",
       "          0.02017119,  0.02601827],\n",
       "        [ 0.0451188 ,  0.0175558 ,  0.04640624, ...,  0.03603176,\n",
       "         -0.00577275, -0.03927144],\n",
       "        ...,\n",
       "        [ 0.00101539,  0.03268779, -0.04650518, ...,  0.04501123,\n",
       "          0.04266984, -0.03577178],\n",
       "        [ 0.00101539,  0.03268779, -0.04650518, ...,  0.04501123,\n",
       "          0.04266984, -0.03577178],\n",
       "        [ 0.00101539,  0.03268779, -0.04650518, ...,  0.04501123,\n",
       "          0.04266984, -0.03577178]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(vectorize([x_train_raw[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>It's time to develop the model. In this case, I will be using a simple model for training.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_text\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 314)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 314, 256)          83501568  \n",
      "                                                                 \n",
      " first_conf (Conv1D)         (None, 313, 256)          131328    \n",
      "                                                                 \n",
      " second_conf (Conv1D)        (None, 311, 256)          196864    \n",
      "                                                                 \n",
      " third_conv (Conv1D)         (None, 309, 256)          196864    \n",
      "                                                                 \n",
      " g_pool (GlobalAveragePoolin  (None, 256)              0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dense_bro (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " final_dense (Dense)         (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,060,165\n",
      "Trainable params: 84,060,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = vectorize(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.Conv1D(filters=256, kernel_size=2, activation=\"relu\", name=\"first_conf\")(x)\n",
    "x = tf.keras.layers.Conv1D(filters=256, kernel_size=3, activation=\"relu\", name=\"second_conf\")(x)\n",
    "x = tf.keras.layers.Conv1D(filters=256, kernel_size=3, padding=\"valid\", activation=\"relu\", name=\"third_conv\")(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D(name=\"g_pool\")(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"dense_bro\")(x)\n",
    "outputs = tf.keras.layers.Dense(len(set(y_train_raw)), activation=\"softmax\", name=\"final_dense\")(x)\n",
    "model_text = tf.keras.Model(inputs, outputs, name=\"model_text\")\n",
    "model_text.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Define callbacks for updating the learning rate, early stopping if the model does not show improvement, and saving the model if any improvement occurs.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", # quantity to be monitored.\n",
    "                                                   factor=0.2, # factor by which the learning rate will be reduced. new_lr = lr * factor.\n",
    "                                                   patience=2, # number of epochs with no improvement after which learning rate will be reduced.\n",
    "                                                   min_lr=1e-7) # lower bound on the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
    "                                               patience=2, # number of epochs with no improvement after which training will be stopped.\n",
    "                                               start_from_epoch=5,\n",
    "                                               mode=\"min\") # training will stop when the quantity monitored has stopped decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoint/model-1/ckpt-{epoch:02d}-{loss:.4f}.ckpt\",\n",
    "                                                   monitor=\"val_loss\",\n",
    "                                                   save_best_only=True,\n",
    "                                                   save_weights_only=False,\n",
    "                                                   mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Define the metrics to be displayed during the training process.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Now let's proceed with training the model.</font>\n",
    "    \n",
    "    For demonstration purposes, I will train this model for only 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "\n",
    "train = train.batch(BATCH_SIZE).cache()\n",
    "test = test.batch(BATCH_SIZE).cache()\n",
    "val = val.batch(BATCH_SIZE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                   metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 17:17:30.500525: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [2211861]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-06 17:17:32.122129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-06 17:17:32.782150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-04-06 17:17:32.783607: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f27679bfcb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-06 17:17:32.783628: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-04-06 17:17:32.786813: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-06 17:17:32.887588: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69121/69121 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.8123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 17:33:35.907746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [28932]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-06 17:33:40.365536: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-04-06 17:33:40.405102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-04-06 17:33:40.842313: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-06 17:33:40.859133: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-06 17:33:40.925739: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-04-06 17:33:40.967380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-06 17:33:40.976605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n",
      "2023-04-06 17:33:41.565993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node serving_default_input_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/model-1/ckpt-01-0.5080.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/model-1/ckpt-01-0.5080.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69121/69121 [==============================] - 974s 14ms/step - loss: 0.5080 - accuracy: 0.8123 - val_loss: 0.4289 - val_accuracy: 0.8437 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "69121/69121 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.8499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 17:49:06.326215: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-04-06 17:49:06.365137: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-04-06 17:49:06.397414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-06 17:49:06.406184: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-06 17:49:06.430334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-04-06 17:49:06.452141: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-06 17:49:06.460936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n",
      "2023-04-06 17:49:06.936406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node serving_default_input_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/model-1/ckpt-02-0.4131.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/model-1/ckpt-02-0.4131.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69121/69121 [==============================] - 929s 13ms/step - loss: 0.4131 - accuracy: 0.8499 - val_loss: 0.4044 - val_accuracy: 0.8503 - lr: 1.0000e-04\n",
      "Epoch 3/5\n",
      "69119/69121 [============================>.] - ETA: 0s - loss: 0.3777 - accuracy: 0.8632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 18:04:35.998590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-04-06 18:04:36.037432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-04-06 18:04:36.070721: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-06 18:04:36.079648: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-06 18:04:36.103898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-04-06 18:04:36.125743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-06 18:04:36.134507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n",
      "2023-04-06 18:04:36.610558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input_1' with dtype string and shape [?,1]\n",
      "\t [[{{node serving_default_input_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/model-1/ckpt-03-0.3777.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoint/model-1/ckpt-03-0.3777.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69121/69121 [==============================] - 927s 13ms/step - loss: 0.3777 - accuracy: 0.8632 - val_loss: 0.3981 - val_accuracy: 0.8535 - lr: 1.0000e-04\n",
      "Epoch 4/5\n",
      "13524/69121 [====>.........................] - ETA: 12:17 - loss: 0.3600 - accuracy: 0.8701"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "history_text = model_text.fit(train,\n",
    "                              epochs=EPOCHS,\n",
    "                              validation_data=val,\n",
    "                              validation_steps=len(val),\n",
    "                              callbacks=[lr_callback, es_callback, save_callback])\n",
    "end_time = time.perf_counter()\n",
    "print(end_time - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_text.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Let's evaluate our model using the testing data to assess its performance.</font>\n",
    "\n",
    "    I'll load our saved model from the checkpoint, assuming that our latest saved model is the best one. Here it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_text = tf.keras.models.load_model(\"checkpoint/model-1/ckpt-05-1.4315.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "922/922 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_text_pred = load_model_text.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29493, 5)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_text_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>We can analyze the detailed performance of our model in predicting each class by visualizing a confusion matrix.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y_test=None, y_pred=None, class_names=None):\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    a = ax.matshow(cm, cmap=plt.cm.Greens)  \n",
    "    \n",
    "    fig.colorbar(a)  \n",
    "    \n",
    "    ax.set(title=\"Confusion Matrix\",\n",
    "             xlabel=\"Predicted label\",\n",
    "             ylabel=\"Actual label\",\n",
    "             xticks=np.arange(len(class_names)), \n",
    "             yticks=np.arange(len(class_names)), \n",
    "             xticklabels=class_names,  \n",
    "             yticklabels=class_names)\n",
    "    \n",
    "    ax.xaxis.set_label_position(\"bottom\")\n",
    "    ax.xaxis.tick_bottom()\n",
    "    \n",
    "    plt.xticks(rotation=70, fontsize=2)\n",
    "    plt.yticks(fontsize=2)\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, f\"{cm[i, j]}\",\n",
    "                  horizontalalignment=\"center\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix(y_test, y_pred=None, class_names=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Let's create a character-level model and evaluate its performance in comparison to our previous training model.</font>\n",
    "    \n",
    "    First, we need to process the data to format it for character-level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw_char = [' ' . join(x) for x in x_train_raw]\n",
    "x_test_raw_char = [' ' . join(x) for x in x_test_raw]\n",
    "x_val_raw_char = [' ' . join(x) for x in x_val_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T h e   e m e r g e n c e   o f   H I V   a s   a   c h r o n i c   c o n d i t i o n   m e a n s   t h a t   p e o p l e   l i v i n g   w i t h   H I V   a r e   r e q u i r e d   t o   t a k e   m o r e   r e s p o n s i b i l i t y   f o r   t h e   s e l f - m a n a g e m e n t   o f   t h e i r   c o n d i t i o n   ,   i n c l u d i n g   m a k i n g   p h y s i c a l   ,   e m o t i o n a l   a n d   s o c i a l   a d j u s t m e n t s   .',\n",
       " 'T h i s   p a p e r   d e s c r i b e s   t h e   d e s i g n   a n d   e v a l u a t i o n   o f   P o s i t i v e   O u t l o o k   ,   a n   o n l i n e   p r o g r a m   a i m i n g   t o   e n h a n c e   t h e   s e l f - m a n a g e m e n t   s k i l l s   o f   g a y   m e n   l i v i n g   w i t h   H I V   .',\n",
       " 'T h i s   s t u d y   i s   d e s i g n e d   a s   a   r a n d o m i s e d   c o n t r o l l e d   t r i a l   i n   w h i c h   m e n   l i v i n g   w i t h   H I V   i n   A u s t r a l i a   w i l l   b e   a s s i g n e d   t o   e i t h e r   a n   i n t e r v e n t i o n   g r o u p   o r   u s u a l   c a r e   c o n t r o l   g r o u p   .']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_raw_char[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_char = tf.data.Dataset.from_tensor_slices((x_train_raw_char, y_train_raw_en))\n",
    "x_test_char = tf.data.Dataset.from_tensor_slices((x_test_raw_char, y_test_raw_en))\n",
    "x_val_char = tf.data.Dataset.from_tensor_slices((x_val_raw_char, y_val_raw_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Now we will create our character-level vectorization and embedding.</font>\n",
    "\n",
    "    APPROXIMATE_CHAR_COUNT: It's important to note that unlike token embedding, where we set the embedding and vectorization based on the number of distinct tokens in our dataset, for character embedding we will need to consider the number of characters in the alphabet, the number of digits, the number of punctuation marks, and also add two additional counts for space and unrecognized character symbols.\n",
    "    \n",
    "    SEQ_LENGTH_CHAR: I will be using the same sequence length for character embedding and vectorization as we used for token embedding and vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APPROXIMATE_CHAR_COUNT = len(string.ascii_lowercase + string.digits + string.punctuation) + 2\n",
    "SEQ_LENGTH_CHAR = SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_char = tf.keras.layers.TextVectorization(max_tokens=APPROXIMATE_CHAR_COUNT,\n",
    "                                              output_mode=\"int\",\n",
    "                                              output_sequence_length=SEQ_LENGTH_CHAR,\n",
    "                                              split=\"whitespace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "vectorize_char.adapt(x_train_raw_char, batch_size=32)\n",
    "end_time = time.perf_counter()\n",
    "print(end_time - start_time, 'seconds') # 890.2296672859957 seconds in average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_char([x_train_raw_char[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_char = tf.keras.layers.Embedding(input_dim=APPROXIMATE_CHAR_COUNT, \n",
    "                                      output_dim=256, \n",
    "                                      input_length=SEQ_LENGTH_CHAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_char(vectorize_char([x_train_raw_char[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Now it's time to design the architecture for our character-level model. I will be using the same architecture as our token-level model.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = vectorize_char(inputs)\n",
    "x = embedding_char(x)\n",
    "x = tf.keras.layers.Conv1D(filters=256, kernel_size=2, activation=\"relu\", name=\"first_conf\")(x)\n",
    "x = tf.keras.layers.Conv1D(filters=256, kernel_size=3, activation=\"relu\", name=\"second_conf\")(x)\n",
    "x = tf.keras.layers.Conv1D(filters=256, kernel_size=3, padding=\"valid\", activation=\"relu\", name=\"third_conv\")(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D(name=\"g_pool\")(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"dense_bro\")(x)\n",
    "outputs = tf.keras.layers.Dense(len(set(y_train_raw)), activation=\"softmax\", name=\"final_dense\")(x)\n",
    "model_char = tf.keras.Model(inputs, outputs, name=\"model_text\")\n",
    "model_char.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Similar to the token-level model, I will incorporate techniques such as learning rate updates, early stopping, and model checkpointing in our character-level model.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", # quantity to be monitored.\n",
    "                                                   factor=0.2, # factor by which the learning rate will be reduced. new_lr = lr * factor.\n",
    "                                                   patience=2, # number of epochs with no improvement after which learning rate will be reduced.\n",
    "                                                   min_lr=1e-7) # lower bound on the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
    "                                               patience=2, # number of epochs with no improvement after which training will be stopped.\n",
    "                                               start_from_epoch=5,\n",
    "                                               mode=\"min\") # training will stop when the quantity monitored has stopped decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoint/model-2/ckpt-{epoch:02d}-{loss:.4f}.ckpt\",\n",
    "                                                   monitor=\"val_loss\",\n",
    "                                                   save_best_only=True,\n",
    "                                                   save_weights_only=False,\n",
    "                                                   mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Let's compile and train the model now.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    " \n",
    "train_char = x_train_char.batch(BATCH_SIZE).cache()\n",
    "test_char = x_test_char.batch(BATCH_SIZE).cache()\n",
    "val_char = x_val_char.batch(BATCH_SIZE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_char.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                   metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "history_char = model_char.fit(train_char,\n",
    "                              epochs=EPOCHS,\n",
    "                              validation_data=val_char,\n",
    "                              validation_steps=len(val_char),\n",
    "                              callbacks=[lr_callback, es_callback, save_callback])\n",
    "end_time = time.perf_counter()\n",
    "print(end_time - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_char.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
